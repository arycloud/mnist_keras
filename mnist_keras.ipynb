{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arycloud/mnist_keras/blob/master/mnist_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ou6CMbmqi-YL",
        "colab_type": "code",
        "outputId": "57e52967-5f17-4706-baf0-e0d19b82bf2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9lQDoCxAj7ow",
        "colab_type": "code",
        "outputId": "32bb0c3c-97d4-4351-e01a-0144592e4937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imshow(x_train[1])\n",
        "# plt.show()\n",
        "print(x_train[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
            "  159  50   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
            "  252 237   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
            "  233 252  57   6   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
            "   84 252 253 122   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
            "   96 189 253 167   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
            "   47  79 255 168   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
            "    0   0 253 243  50   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
            "    0   0 253 252 165   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
            "    0   0 253 252 195   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
            "    0   0 255 253 196   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
            "    0   0 253 252 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
            "    7 135 253 186  12   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
            "  131 252 225  71   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
            "  252 173   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
            "  162   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
            "   56   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QveWF29ZnVkx",
        "colab_type": "code",
        "outputId": "f4906db7-55ae-4d30-ca12-0aed006419cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2369
        }
      },
      "cell_type": "code",
      "source": [
        "# So, we need to normalize our data\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
        "\n",
        "print(x_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.08216044 0.2286589  0.3728098\n",
            "  0.30506548 0.08583808 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.08087653 0.38341541 0.36240278 0.37133624\n",
            "  0.48350001 0.4068725  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.08861609 0.3824786  0.40758025 0.36240278 0.35218\n",
            "  0.44704564 0.43262392 0.06832372 0.00859123 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01621743\n",
            "  0.095788   0.36759266 0.42460179 0.40758025 0.36240278 0.29765841\n",
            "  0.16116667 0.43262392 0.30326141 0.17468832 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.26434406\n",
            "  0.4023096  0.41354174 0.42460179 0.40758025 0.36240278 0.37133624\n",
            "  0.18419048 0.32446794 0.30326141 0.23912253 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.08411834 0.38597476\n",
            "  0.40390606 0.41518278 0.32013627 0.18365276 0.36384089 0.33597088\n",
            "  0.09017659 0.13562417 0.30565873 0.2405544  0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.07427511 0.39255225 0.40867916\n",
            "  0.4023096  0.29374592 0.02021913 0.12082418 0.17401086 0.03094469\n",
            "  0.         0.         0.30326141 0.34794476 0.12263192 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.04890249 0.2553207  0.41729294 0.37786605\n",
            "  0.33206506 0.13784725 0.         0.         0.         0.\n",
            "  0.         0.         0.30326141 0.36083161 0.40468535 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.00966301 0.22906954 0.38994434 0.39585101 0.11514373\n",
            "  0.03033287 0.04594908 0.         0.         0.         0.\n",
            "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.07868449 0.32430069 0.38994434 0.10391089 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.27332506 0.3255876  0.29400565 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.30565873 0.36226348 0.48071715 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.33960736 0.33958568 0.32430069 0.17330859 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.30326141 0.36083161 0.3629905  0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.37982402 0.34786826 0.29598873 0.03868495 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.01343056 0.23176282 0.30326141 0.26632809 0.02943166 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.37982402 0.34786826 0.28698037 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.0103149\n",
            "  0.25134326 0.43262392 0.26969888 0.10166287 0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.37982402 0.34786826 0.18660159 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.0690291  0.24313682\n",
            "  0.48350001 0.29699976 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.38429254 0.34924869 0.28955419 0.         0.         0.\n",
            "  0.         0.         0.         0.18365276 0.34226929 0.3728098\n",
            "  0.31082143 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.37982402 0.34786826 0.32043997 0.22592013 0.0791702  0.04703054\n",
            "  0.13569967 0.29210488 0.37910874 0.40758025 0.3206977  0.24608394\n",
            "  0.10744445 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.37982402 0.34786826 0.32430069 0.38994434 0.37770784 0.34867468\n",
            "  0.4023096  0.41354174 0.42460179 0.31575387 0.18695382 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.1251185  0.27470549 0.32430069 0.38994434 0.41729294 0.40867916\n",
            "  0.4023096  0.38236201 0.24431452 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.03451074 0.16472416 0.38994434 0.41729294 0.40867916\n",
            "  0.2251018  0.06071843 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B4e_t-tCpV0t",
        "colab_type": "code",
        "outputId": "322eb81e-9fb8-4eca-ce98-c8345d1712bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "# Now, it's normalized, the values between 1 & 0\n",
        "# let's bild the model\n",
        "\n",
        "# Build the model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 9s 145us/sample - loss: 0.2639 - acc: 0.9230\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.1070 - acc: 0.9672\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0717 - acc: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f913d73c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "UhABJ_qfqQ2z",
        "colab_type": "code",
        "outputId": "2f05c8c8-39ae-4dd1-be46-aabd4d2a149f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "loss_val, accu_val = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(loss_val, accu_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 62us/sample - loss: 0.0907 - acc: 0.9715\n",
            "0.09074438300398179 0.9715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-JGKWEZ3r0Q2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('num_reader_from_pic_model.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5A0htQOsMuR",
        "colab_type": "code",
        "outputId": "1ff9a61f-50c4-44d7-96e7-195f1aa182fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('num_reader_from_pic_model.model')\n",
        "predictions = new_model.predict(x_test)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
            "[[2.3906812e-09 2.4146546e-08 8.2128179e-05 ... 9.9991512e-01\n",
            "  1.1738294e-08 5.4925714e-08]\n",
            " [1.1503975e-08 1.2680299e-04 9.9987185e-01 ... 2.2191402e-09\n",
            "  1.0426265e-09 9.9167983e-13]\n",
            " [8.1629558e-08 9.9997818e-01 2.3274833e-06 ... 1.4485043e-05\n",
            "  1.0212667e-06 1.6599741e-07]\n",
            " ...\n",
            " [1.5917696e-07 2.8592635e-06 1.3803155e-07 ... 2.7054200e-05\n",
            "  7.9224956e-06 1.2989523e-04]\n",
            " [1.2153588e-06 5.4111689e-07 3.6478692e-08 ... 1.6346326e-07\n",
            "  6.8190799e-04 3.1865138e-08]\n",
            " [1.7728073e-05 2.2446304e-08 3.8694772e-08 ... 4.5509438e-10\n",
            "  3.6391583e-08 9.8542499e-09]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O2C17Io_sUHq",
        "colab_type": "code",
        "outputId": "b435172f-4aeb-4f97-8f21-616d5df34c9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predictions[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Umqvs4hjsvK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}